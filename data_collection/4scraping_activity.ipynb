{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a71eed-2af7-4e74-97c4-ecff9d7043b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a39af9-6f19-4b1d-91d3-28086d4f3b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data from page1\n",
      "Downloaded data from page2\n",
      "Downloaded data from page3\n",
      "Downloaded data from page4\n",
      "Downloaded data from page5\n",
      "Downloaded data from page6\n",
      "Downloaded data from page7\n",
      "Downloaded data from page8\n",
      "Downloaded data from page9\n",
      "Downloaded data from page10\n",
      "No valid pages anymore...\n"
     ]
    }
   ],
   "source": [
    "#Fetch data & store it\n",
    "page_count = 1\n",
    "\n",
    "while True:\n",
    "    URL = (f\"https://quotes.toscrape.com/page/{page_count}/\")\n",
    "    res = req.get(URL)\n",
    "\n",
    "    soup = BeautifulSoup(res.text, \"lxml\")\n",
    "    quotes = soup.select(\"div.quote\")\n",
    "\n",
    "    if not quotes:\n",
    "        print(\"No valid pages anymore...\")\n",
    "        break\n",
    "\n",
    "    with open(f\"scraped_data/page{page_count}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(res.text)\n",
    "        print(f\"Downloaded data from page{page_count}\")\n",
    "\n",
    "    page_count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e9732f2-1c1a-40e8-8b4f-87518793404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT USEFUL INFO - PAGE1\n",
    "with open(f\"scraped_data/page1.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10302674-9724-4d21-8f96-205b00840af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'Albert Einstein'], ['“It is better to be hated for what you are than to be loved for what you are not.”', 'André Gide']]\n"
     ]
    }
   ],
   "source": [
    "all_quotes = soup.select(\"div.quote\")\n",
    "life_quotes = []\n",
    "\n",
    "for q in all_quotes:\n",
    "    all_tags = []\n",
    "    \n",
    "    for tag in q.select(\".tags .tag\"):\n",
    "        all_tags.append(tag.get_text())\n",
    "\n",
    "    if \"life\" in all_tags:\n",
    "        text = q.select_one(\"span.text\").get_text()\n",
    "        author = q.select_one(\"small.author\").get_text()\n",
    "        life_quotes.append([text, author])\n",
    "\n",
    "print(life_quotes)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2468bab-d28d-4c8b-ae3e-a443e6ca4acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
